{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Analysis and Forecasting Examples\n",
    "\n",
    "This notebook demonstrates the functionality of the specialized-viz time series module. We'll cover:\n",
    "1. Basic Analysis\n",
    "2. Feature Engineering\n",
    "3. Different Forecasting Models\n",
    "4. Evaluation and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\belgu\\anaconda3\\envs\\github\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "from specialized_viz.timeseries import (\n",
    "    TimeseriesAnalysis,\n",
    "    TimeseriesConfig,\n",
    "    TimeseriesVisualizer,\n",
    "    TimeseriesForecasting\n",
    ")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Prepare Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 1006 rows of data for AAPL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Download sample data\n",
    "ticker = 'AAPL'\n",
    "stock_data = yf.download(ticker, start='2020-01-01', end='2023-12-31')\n",
    "print(f\"Downloaded {len(stock_data)} rows of data for {ticker}\")\n",
    "stock_data.head()\n",
    "data_dict = {\n",
    "    \"Close\": stock_data[\"Close\"][ticker],\n",
    "    \"Open\": stock_data[\"Open\"][ticker],\n",
    "    \"High\": stock_data[\"High\"][ticker],\n",
    "    \"Low\": stock_data[\"Low\"][ticker],\n",
    "    \"Volume\": stock_data[\"Volume\"][ticker],\n",
    "}\n",
    "data = pd.DataFrame(data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Basic Time Series Analysis\n",
    "Let's analyze the components of our time series using decomposition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TimeseriesVisualizer' object has no attribute 'plot_decomposition'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m viz \u001b[38;5;241m=\u001b[39m TimeseriesVisualizer(analyzer)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Plot decomposition\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m decomp_fig \u001b[38;5;241m=\u001b[39m \u001b[43mviz\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot_decomposition\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClose\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     19\u001b[0m decomp_fig\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'TimeseriesVisualizer' object has no attribute 'plot_decomposition'"
     ]
    }
   ],
   "source": [
    "# Initialize analyzer with configuration\n",
    "config = TimeseriesConfig(\n",
    "    decomposition_method='additive',\n",
    "    seasonal_periods=[5, 21, 63, 252]  # Daily, Weekly, Monthly, Yearly\n",
    ")\n",
    "analyzer = TimeseriesAnalysis(data, config)\n",
    "\n",
    "# Decompose the time series using daily seasonality (5 trading days)\n",
    "decomposition = analyzer.decompose('Close', period=5)  # Using 5 for weekly trading pattern\n",
    "\n",
    "# You can also analyze monthly seasonality\n",
    "monthly_decomposition = analyzer.decompose('Close', period=21)  # Using 21 for monthly trading pattern\n",
    "\n",
    "# Initialize visualizer\n",
    "viz = TimeseriesVisualizer(analyzer)\n",
    "\n",
    "# Plot decomposition\n",
    "decomp_fig = viz.plot_decomposition('Close')\n",
    "decomp_fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available methods: ['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'analyzer']\n"
     ]
    }
   ],
   "source": [
    "print(\"Available methods:\", dir(viz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File contents:\n",
      "class TimeseriesVisualizer:\n",
      "    \"\"\"Enhanced visualization class for time series analysis.\"\"\"\n",
      "    \n",
      "    def __init__(self, analyzer: TimeseriesAnalysis):\n",
      "        \"\"\"Initialize visualizer with analyzer instance.\"\"\"\n",
      "        self.analyzer = analyzer\n",
      "        self.color_scheme = {\n",
      "            'primary': '#1f77b4',\n",
      "            'secondary': '#ff7f0e',\n",
      "            'tertiary': '#2ca02c',\n",
      "            'quaternary': '#d62728',\n",
      "            'background': '#ffffff',\n",
      "            'grid': '#e0e0e0'\n",
      "        }\n",
      "        \n",
      "    def plot_correlogram(self, column: str) -> go.Figure:\n",
      "        \"\"\"Create advanced correlation visualization.\n",
      "        \n",
      "        Args:\n",
      "            column: Name of the column to analyze\n",
      "            \n",
      "        Returns:\n",
      "            Plotly figure with correlation analysis\n",
      "        \"\"\"\n",
      "        series = self.analyzer.data[column]\n",
      "        \n",
      "        fig = make_subplots(\n",
      "            rows=2, cols=2,\n",
      "            subplot_titles=(\n",
      "                'Autocorrelation Function (ACF)',\n",
      "                'Partial Autocorrelation (PACF)',\n",
      "                'Rolling Correlation',\n",
      "                'Correlation Heatmap'\n",
      "            )\n",
      "        )\n",
      "        \n",
      "        # ACF Plot\n",
      "        acf_values = pd.Series(series).autocorr(lag=None)\n",
      "        fig.add_trace(\n",
      "            go.Bar(\n",
      "                x=list(range(len(acf_values))),\n",
      "                y=acf_values,\n",
      "                name='ACF'\n",
      "            ),\n",
      "            row=1, col=1\n",
      "        )\n",
      "        \n",
      "        # PACF Plot\n",
      "        from statsmodels.tsa.stattools import pacf\n",
      "        pacf_values = pacf(series.dropna())\n",
      "        fig.add_trace(\n",
      "            go.Bar(\n",
      "                x=list(range(len(pacf_values))),\n",
      "                y=pacf_values,\n",
      "                name='PACF'\n",
      "            ),\n",
      "            row=1, col=2\n",
      "        )\n",
      "        \n",
      "        # Rolling Correlation\n",
      "        rolling_corr = series.rolling(window=30).corr(\n",
      "            series.shift(1)\n",
      "        )\n",
      "        fig.add_trace(\n",
      "            go.Scatter(\n",
      "                x=series.index,\n",
      "                y=rolling_corr,\n",
      "                name='Rolling Correlation'\n",
      "            ),\n",
      "            row=2, col=1\n",
      "        )\n",
      "        \n",
      "        # Correlation Heatmap\n",
      "        if isinstance(self.analyzer.data, pd.DataFrame):\n",
      "            corr_matrix = self.analyzer.data.corr()\n",
      "            fig.add_trace(\n",
      "                go.Heatmap(\n",
      "                    z=corr_matrix.values,\n",
      "                    x=corr_matrix.columns,\n",
      "                    y=corr_matrix.columns,\n",
      "                    colorscale='RdBu'\n",
      "                ),\n",
      "                row=2, col=2\n",
      "            )\n",
      "            \n",
      "        fig.update_layout(height=800, width=1200, showlegend=False)\n",
      "        return fig\n",
      "        \n",
      "    def plot_distribution_evolution(self, column: str) -> go.Figure:\n",
      "        \"\"\"Create distribution analysis over time.\n",
      "        \n",
      "        Args:\n",
      "            column: Name of the column to analyze\n",
      "            \n",
      "        Returns:\n",
      "            Plotly figure with distribution analysis\n",
      "        \"\"\"\n",
      "        series = self.analyzer.data[column]\n",
      "        \n",
      "        fig = make_subplots(\n",
      "            rows=2, cols=2,\n",
      "            subplot_titles=(\n",
      "                'Rolling Probability Density',\n",
      "                'Quantile Plot',\n",
      "                'Box Plot Over Time',\n",
      "                'Violin Plot by Period'\n",
      "            )\n",
      "        )\n",
      "        \n",
      "        # Rolling Probability Density\n",
      "        from scipy import stats\n",
      "        windows = np.array_split(series, 4)  # Split into 4 periods\n",
      "        for i, window in enumerate(windows):\n",
      "            kernel = stats.gaussian_kde(window.dropna())\n",
      "            x_range = np.linspace(series.min(), series.max(), 100)\n",
      "            fig.add_trace(\n",
      "                go.Scatter(\n",
      "                    x=x_range,\n",
      "                    y=kernel(x_range),\n",
      "                    name=f'Period {i+1}',\n",
      "                    line=dict(color=px.colors.qualitative.Set3[i])\n",
      "                ),\n",
      "                row=1, col=1\n",
      "            )\n",
      "            \n",
      "        # Quantile Plot\n",
      "        fig.add_trace(\n",
      "            go.Scatter(\n",
      "                x=series.sort_values(),\n",
      "                y=stats.norm.ppf(np.linspace(0.01, 0.99, len(series))),\n",
      "                mode='markers',\n",
      "                name='Q-Q Plot'\n",
      "            ),\n",
      "            row=1, col=2\n",
      "        )\n",
      "        \n",
      "        # Box Plot Over Time\n",
      "        df_box = pd.DataFrame({\n",
      "            'value': series.values,\n",
      "            'period': pd.qcut(np.arange(len(series)), 4)\n",
      "        })\n",
      "        fig.add_trace(\n",
      "            go.Box(\n",
      "                x=df_box['period'].astype(str),\n",
      "                y=df_box['value'],\n",
      "                name='Box Plot'\n",
      "            ),\n",
      "            row=2, col=1\n",
      "        )\n",
      "        \n",
      "        # Violin Plot\n",
      "        df_violin = pd.DataFrame({\n",
      "            'value': series.values,\n",
      "            'period': series.index.month\n",
      "        })\n",
      "        fig.add_trace(\n",
      "            go.Violin(\n",
      "                x=df_violin['period'].astype(str),\n",
      "                y=df_violin['value'],\n",
      "                name='Violin Plot',\n",
      "                box_visible=True\n",
      "            ),\n",
      "            row=2, col=2\n",
      "        )\n",
      "        \n",
      "        fig.update_layout(height=800, width=1200, showlegend=True)\n",
      "        return fig\n",
      "        \n",
      "    def create_animation(self, column: str) -> go.Figure:\n",
      "        \"\"\"Create animated visualizations.\n",
      "        \n",
      "        Args:\n",
      "            column: Name of the column to analyze\n",
      "            \n",
      "        Returns:\n",
      "            Plotly figure with animation frames\n",
      "        \"\"\"\n",
      "        series = self.analyzer.data[column]\n",
      "        \n",
      "        # Create frames for animation\n",
      "        frames = []\n",
      "        window_size = len(series) // 10  # 10 frames\n",
      "        \n",
      "        for i in range(0, len(series) - window_size, window_size // 2):\n",
      "            window = series.iloc[i:i+window_size]\n",
      "            \n",
      "            # Trend analysis for window\n",
      "            X = np.arange(len(window)).reshape(-1, 1)\n",
      "            y = window.values.reshape(-1, 1)\n",
      "            from sklearn.linear_model import LinearRegression\n",
      "            model = LinearRegression()\n",
      "            model.fit(X, y)\n",
      "            trend = model.predict(X)\n",
      "            \n",
      "            frame = go.Frame(\n",
      "                data=[\n",
      "                    go.Scatter(\n",
      "                        x=window.index,\n",
      "                        y=window.values,\n",
      "                        name='Original',\n",
      "                        mode='lines'\n",
      "                    ),\n",
      "                    go.Scatter(\n",
      "                        x=window.index,\n",
      "                        y=trend.flatten(),\n",
      "                        name='Trend',\n",
      "                        line=dict(color='red', dash='dash')\n",
      "                    )\n",
      "                ],\n",
      "                name=f'frame{i}'\n",
      "            )\n",
      "            frames.append(frame)\n",
      "            \n",
      "        # Create base figure\n",
      "        fig = go.Figure(\n",
      "            data=frames[0].data,\n",
      "            frames=frames,\n",
      "        )\n",
      "        \n",
      "        # Add slider and play button\n",
      "        fig.update_layout(\n",
      "            updatemenus=[{\n",
      "                'type': 'buttons',\n",
      "                'showactive': False,\n",
      "                'buttons': [{\n",
      "                    'label': 'Play',\n",
      "                    'method': 'animate',\n",
      "                    'args': [None, {\n",
      "                        'frame': {'duration': 500, 'redraw': True},\n",
      "                        'fromcurrent': True,\n",
      "                        'transition': {'duration': 300}\n",
      "                    }]\n",
      "                }]\n",
      "            }],\n",
      "            sliders=[{\n",
      "                'currentvalue': {'prefix': 'Frame: '},\n",
      "                'steps': [{'args': [[f.name], {'mode': 'immediate'}],\n",
      "                          'label': str(k),\n",
      "                          'method': 'animate'} for k, f in enumerate(frames)]\n",
      "            }]\n",
      "        )\n",
      "        \n",
      "        return fig\n",
      "        \n",
      "    def plot_feature_importance(self, \n",
      "                              features: pd.DataFrame,\n",
      "                              target: pd.Series) -> go.Figure:\n",
      "        \"\"\"Create feature importance visualization.\n",
      "        \n",
      "        Args:\n",
      "            features: Feature DataFrame\n",
      "            target: Target series\n",
      "            \n",
      "        Returns:\n",
      "            Plotly figure with feature importance analysis\n",
      "        \"\"\"\n",
      "        fig = make_subplots(\n",
      "            rows=2, cols=2,\n",
      "            subplot_titles=(\n",
      "                'SHAP Values',\n",
      "                'Feature Correlation',\n",
      "                'Temporal Importance',\n",
      "                'Impact Analysis'\n",
      "            )\n",
      "        )\n",
      "        \n",
      "        # SHAP Values\n",
      "        from sklearn.ensemble import RandomForestRegressor\n",
      "        model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
      "        model.fit(features, target)\n",
      "        \n",
      "        explainer = shap.TreeExplainer(model)\n",
      "        shap_values = explainer.shap_values(features)\n",
      "        \n",
      "        fig.add_trace(\n",
      "            go.Bar(\n",
      "                x=features.columns,\n",
      "                y=np.abs(shap_values).mean(0),\n",
      "                name='SHAP Values'\n",
      "            ),\n",
      "            row=1, col=1\n",
      "        )\n",
      "        \n",
      "        # Feature Correlation\n",
      "        corr_matrix = features.corr()\n",
      "        fig.add_trace(\n",
      "            go.Heatmap(\n",
      "                z=corr_matrix.values,\n",
      "                x=corr_matrix.columns,\n",
      "                y=corr_matrix.columns,\n",
      "                colorscale='RdBu'\n",
      "            ),\n",
      "            row=1, col=2\n",
      "        )\n",
      "        \n",
      "        # Temporal Importance\n",
      "        importance_over_time = pd.DataFrame(\n",
      "            index=features.index,\n",
      "            columns=features.columns\n",
      "        )\n",
      "        \n",
      "        window_size = len(features) // 10\n",
      "        for i in range(0, len(features) - window_size, window_size):\n",
      "            window_features = features.iloc[i:i+window_size]\n",
      "            window_target = target.iloc[i:i+window_size]\n",
      "            model.fit(window_features, window_target)\n",
      "            importance_over_time.iloc[i:i+window_size] = model.feature_importances_\n",
      "            \n",
      "        for column in features.columns:\n",
      "            fig.add_trace(\n",
      "                go.Scatter(\n",
      "                    x=importance_over_time.index,\n",
      "                    y=importance_over_time[column],\n",
      "                    name=column\n",
      "                ),\n",
      "                row=2, col=1\n",
      "            )\n",
      "            \n",
      "        # Impact Analysis\n",
      "        impact_scores = []\n",
      "        for column in features.columns:\n",
      "            shuffled = features.copy()\n",
      "            shuffled[column] = np.random.permutation(shuffled[column])\n",
      "            model_shuffled = RandomForestRegressor(n_estimators=100, random_state=42)\n",
      "            model_shuffled.fit(shuffled, target)\n",
      "            impact = mean_squared_error(target, model.predict(features)) - \\\n",
      "                    mean_squared_error(target, model_shuffled.predict(shuffled))\n",
      "            impact_scores.append(impact)\n",
      "            \n",
      "        fig.add_trace(\n",
      "            go.Bar(\n",
      "                x=features.columns,\n",
      "                y=impact_scores,\n",
      "                name='Feature Impact'\n",
      "            ),\n",
      "            row=2, col=2\n",
      "        )\n",
      "        \n",
      "        fig.update_layout(height=1000, width=1200, showlegend=True)\n",
      "        return fig\n",
      "    \n",
      "    def create_comprehensive_dashboard(self, column: str) -> go.Figure:\n",
      "        \"\"\"Create a comprehensive analysis dashboard.\n",
      "        \n",
      "        Args:\n",
      "            column: Name of the column to analyze\n",
      "            \n",
      "        Returns:\n",
      "            Plotly figure with comprehensive dashboard\n",
      "        \"\"\"\n",
      "        fig = make_subplots(\n",
      "            rows=3, cols=3,\n",
      "            subplot_titles=(\n",
      "                'Time Series Plot',\n",
      "                'Decomposition',\n",
      "                'Seasonality Analysis',\n",
      "                'Anomaly Detection',\n",
      "                'Cycle Analysis',\n",
      "                'Distribution',\n",
      "                'Correlation Analysis',\n",
      "                'Feature Importance',\n",
      "                'Forecasting'\n",
      "            ),\n",
      "            specs=[[{'secondary_y': True}, {'secondary_y': False}, {'secondary_y': False}],\n",
      "                  [{'secondary_y': False}, {'secondary_y': False}, {'secondary_y': False}],\n",
      "                  [{'secondary_y': False}, {'secondary_y': False}, {'secondary_y': False}]]\n",
      "        )\n",
      "        \n",
      "        series = self.analyzer.data[column]\n",
      "        \n",
      "        # 1. Time Series Plot with Moving Averages\n",
      "        fig.add_trace(\n",
      "            go.Scatter(x=series.index, y=series, name='Original',\n",
      "                      line=dict(color=self.color_scheme['primary'])),\n",
      "            row=1, col=1\n",
      "        )\n",
      "        \n",
      "        # Add moving averages\n",
      "        for window in [7, 30]:\n",
      "            ma = series.rolling(window=window).mean()\n",
      "            fig.add_trace(\n",
      "                go.Scatter(x=ma.index, y=ma, name=f'MA-{window}',\n",
      "                          line=dict(dash='dash')),\n",
      "                row=1, col=1\n",
      "            )\n",
      "        \n",
      "        # 2. Decomposition\n",
      "        components = self.analyzer.decompose(column)\n",
      "        fig.add_trace(\n",
      "            go.Scatter(x=components['trend'].index, y=components['trend'],\n",
      "                      name='Trend', line=dict(color=self.color_scheme['secondary'])),\n",
      "            row=1, col=2\n",
      "        )\n",
      "        fig.add_trace(\n",
      "            go.Scatter(x=components['seasonal'].index, y=components['seasonal'],\n",
      "                      name='Seasonal', line=dict(color=self.color_scheme['tertiary'])),\n",
      "            row=1, col=2\n",
      "        )\n",
      "        \n",
      "        # 3. Seasonality Analysis\n",
      "        seasonality = self.analyzer.analyze_seasonality(column)\n",
      "        seasonal_strength = pd.Series(seasonality['seasonal_strength_12'])\n",
      "        fig.add_trace(\n",
      "            go.Bar(x=seasonal_strength.index, y=seasonal_strength.values,\n",
      "                  name='Seasonal Strength'),\n",
      "            row=1, col=3\n",
      "        )\n",
      "        \n",
      "        # 4. Anomaly Detection\n",
      "        anomalies = self.analyzer.detect_anomalies(column)\n",
      "        fig.add_trace(\n",
      "            go.Scatter(x=series.index, y=series, name='Data',\n",
      "                      line=dict(color='lightgrey')),\n",
      "            row=2, col=1\n",
      "        )\n",
      "        \n",
      "        for method, anomaly_series in anomalies.items():\n",
      "            anomaly_points = series[anomaly_series]\n",
      "            fig.add_trace(\n",
      "                go.Scatter(x=anomaly_points.index, y=anomaly_points,\n",
      "                          mode='markers', name=f'Anomalies ({method})',\n",
      "                          marker=dict(size=8, symbol='x')),\n",
      "                row=2, col=1\n",
      "            )\n",
      "        \n",
      "        # 5. Cycle Analysis\n",
      "        cycles = self.analyzer.analyze_cycles(column)\n",
      "        fig.add_trace(\n",
      "            go.Scatter(x=np.arange(len(cycles['fourier']['dominant_frequencies'])),\n",
      "                      y=cycles['fourier']['amplitudes'],\n",
      "                      name='Frequency Components'),\n",
      "            row=2, col=2\n",
      "        )\n",
      "        \n",
      "        # 6. Distribution\n",
      "        fig.add_trace(\n",
      "            go.Histogram(x=series, nbinsx=30, name='Distribution'),\n",
      "            row=2, col=3\n",
      "        )\n",
      "        \n",
      "        # 7. Correlation Analysis\n",
      "        autocorr = pd.Series(series).autocorr(lag=None)\n",
      "        fig.add_trace(\n",
      "            go.Bar(x=np.arange(len(autocorr)), y=autocorr,\n",
      "                  name='Autocorrelation'),\n",
      "            row=3, col=1\n",
      "        )\n",
      "        \n",
      "        # 8. Feature Importance\n",
      "        # Create basic features for demonstration\n",
      "        features = pd.DataFrame({\n",
      "            'lag_1': series.shift(1),\n",
      "            'lag_7': series.shift(7),\n",
      "            'ma_7': series.rolling(7).mean(),\n",
      "            'std_7': series.rolling(7).std()\n",
      "        }).dropna()\n",
      "        \n",
      "        from sklearn.ensemble import RandomForestRegressor\n",
      "        model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
      "        target = series[features.index]\n",
      "        model.fit(features, target)\n",
      "        \n",
      "        importance = pd.Series(model.feature_importances_, index=features.columns)\n",
      "        fig.add_trace(\n",
      "            go.Bar(x=importance.index, y=importance.values,\n",
      "                  name='Feature Importance'),\n",
      "            row=3, col=2\n",
      "        )\n",
      "        \n",
      "        # 9. Forecasting\n",
      "        from sklearn.model_selection import train_test_split\n",
      "        train_size = int(len(features) * 0.8)\n",
      "        train_features = features[:train_size]\n",
      "        test_features = features[train_size:]\n",
      "        train_target = target[:train_size]\n",
      "        test_target = target[train_size:]\n",
      "        \n",
      "        model.fit(train_features, train_target)\n",
      "        predictions = model.predict(test_features)\n",
      "        \n",
      "        fig.add_trace(\n",
      "            go.Scatter(x=test_features.index, y=test_target,\n",
      "                      name='Actual', line=dict(color=self.color_scheme['primary'])),\n",
      "            row=3, col=3\n",
      "        )\n",
      "        fig.add_trace(\n",
      "            go.Scatter(x=test_features.index, y=predictions,\n",
      "                      name='Forecast', line=dict(color=self.color_scheme['secondary'],\n",
      "                                               dash='dash')),\n",
      "            row=3, col=3\n",
      "        )\n",
      "        \n",
      "        # Update layout for each subplot\n",
      "        for i in range(1, 4):\n",
      "            for j in range(1, 4):\n",
      "                fig.update_xaxes(title_text=\"Date\", row=i, col=j)\n",
      "                fig.update_yaxes(title_text=\"Value\", row=i, col=j)\n",
      "        \n",
      "        # Overall layout updates\n",
      "        fig.update_layout(\n",
      "            height=1200,\n",
      "            width=1600,\n",
      "            showlegend=True,\n",
      "            title_text=\"Comprehensive Time Series Analysis Dashboard\",\n",
      "            template=\"plotly_white\",\n",
      "            legend=dict(\n",
      "                orientation=\"h\",\n",
      "                yanchor=\"bottom\",\n",
      "                y=1.02,\n",
      "                xanchor=\"right\",\n",
      "                x=1\n",
      "            )\n",
      "        )\n",
      "        \n",
      "        return fig\n",
      "        \n",
      "    def plot_decomposition(self, column: str, period: int = None) -> go.Figure:\n",
      "        \"\"\"Create decomposition plot showing trend, seasonal, and residual components.\n",
      "        \n",
      "        Args:\n",
      "            column: Name of the column to decompose\n",
      "            period: Optional seasonal period to use\n",
      "            \n",
      "        Returns:\n",
      "            Plotly figure with decomposition plots\n",
      "        \"\"\"\n",
      "        components = self.analyzer.decompose(column, period=period)\n",
      "        \n",
      "        fig = make_subplots(\n",
      "            rows=4, cols=1,\n",
      "            subplot_titles=('Original', 'Trend', 'Seasonal', 'Residual'),\n",
      "            vertical_spacing=0.05\n",
      "        )\n",
      "        \n",
      "        # Plot original data\n",
      "        fig.add_trace(\n",
      "            go.Scatter(\n",
      "                x=self.analyzer.data.index,\n",
      "                y=components['original'],\n",
      "                name='Original',\n",
      "                line=dict(color='blue')\n",
      "            ),\n",
      "            row=1, col=1\n",
      "        )\n",
      "        \n",
      "        # Plot trend\n",
      "        fig.add_trace(\n",
      "            go.Scatter(\n",
      "                x=self.analyzer.data.index,\n",
      "                y=components['trend'],\n",
      "                name='Trend',\n",
      "                line=dict(color='red')\n",
      "            ),\n",
      "            row=2, col=1\n",
      "        )\n",
      "        \n",
      "        # Plot seasonal component\n",
      "        fig.add_trace(\n",
      "            go.Scatter(\n",
      "                x=self.analyzer.data.index,\n",
      "                y=components['seasonal'],\n",
      "                name='Seasonal',\n",
      "                line=dict(color='green')\n",
      "            ),\n",
      "            row=3, col=1\n",
      "        )\n",
      "        \n",
      "        # Plot residual\n",
      "        fig.add_trace(\n",
      "            go.Scatter(\n",
      "                x=self.analyzer.data.index,\n",
      "                y=components['residual'],\n",
      "                name='Residual',\n",
      "                line=dict(color='purple')\n",
      "            ),\n",
      "            row=4, col=1\n",
      "        )\n",
      "        \n",
      "        # Update layout\n",
      "        fig.update_layout(\n",
      "            height=800,\n",
      "            width=1200,\n",
      "            title_text=\"Time Series Decomposition\",\n",
      "            showlegend=True\n",
      "        )\n",
      "        \n",
      "        # Update y-axes titles\n",
      "        fig.update_yaxes(title_text=\"Value\", row=1, col=1)\n",
      "        fig.update_yaxes(title_text=\"Trend\", row=2, col=1)\n",
      "        fig.update_yaxes(title_text=\"Seasonal\", row=3, col=1)\n",
      "        fig.update_yaxes(title_text=\"Residual\", row=4, col=1)\n",
      "        \n",
      "        return fig\n",
      "        \n",
      "    def plot_trend_analysis(self, column: str) -> go.Figure:\n",
      "        \"\"\"Create trend analysis plot.\n",
      "        \n",
      "        Args:\n",
      "            column: Name of the column to analyze\n",
      "            \n",
      "        Returns:\n",
      "            Plotly figure with trend analysis\n",
      "        \"\"\"\n",
      "        trend_analysis = self.analyzer.analyze_trend(column)\n",
      "        \n",
      "        fig = make_subplots(\n",
      "            rows=2, cols=1,\n",
      "            subplot_titles=('Trend Analysis', 'Residuals'),\n",
      "            vertical_spacing=0.15\n",
      "        )\n",
      "        \n",
      "        # Plot original data and trend line\n",
      "        fig.add_trace(\n",
      "            go.Scatter(\n",
      "                x=self.analyzer.data.index,\n",
      "                y=self.analyzer.data[column],\n",
      "                name='Original',\n",
      "                line=dict(color='blue')\n",
      "            ),\n",
      "            row=1, col=1\n",
      "        )\n",
      "        \n",
      "        fig.add_trace(\n",
      "            go.Scatter(\n",
      "                x=self.analyzer.data.index,\n",
      "                y=trend_analysis['trend_line'],\n",
      "                name='Trend Line',\n",
      "                line=dict(color='red', dash='dash')\n",
      "            ),\n",
      "            row=1, col=1\n",
      "        )\n",
      "        \n",
      "        # Add trend statistics as annotations\n",
      "        fig.add_annotation(\n",
      "            xref='paper',\n",
      "            yref='paper',\n",
      "            x=0.02,\n",
      "            y=0.98,\n",
      "            text=f\"Slope: {trend_analysis['slope']:.4f}<br>\" + \\\n",
      "                f\"RÂ²: {trend_analysis['r_squared']:.4f}<br>\" + \\\n",
      "                f\"Trend: {trend_analysis['mann_kendall_stats']['trend']}<br>\" + \\\n",
      "                f\"p-value: {trend_analysis['mann_kendall_stats']['p_value']:.4f}\",\n",
      "            showarrow=False,\n",
      "            bgcolor='rgba(255,255,255,0.8)'\n",
      "        )\n",
      "        \n",
      "        # Plot residuals\n",
      "        residuals = self.analyzer.data[column] - trend_analysis['trend_line']\n",
      "        fig.add_trace(\n",
      "            go.Scatter(\n",
      "                x=self.analyzer.data.index,\n",
      "                y=residuals,\n",
      "                name='Residuals',\n",
      "                line=dict(color='gray')\n",
      "            ),\n",
      "            row=2, col=1\n",
      "        )\n",
      "        \n",
      "        fig.update_layout(\n",
      "            height=800,\n",
      "            width=1200,\n",
      "            title_text=f\"Trend Analysis for {column}\",\n",
      "            showlegend=True\n",
      "        )\n",
      "        \n",
      "        return fig\n",
      "        \n",
      "    def plot_change_points(self, column: str, \n",
      "                        methods: Optional[list] = None) -> go.Figure:\n",
      "        \"\"\"Create change point detection plot.\n",
      "        \n",
      "        Args:\n",
      "            column: Name of the column to analyze\n",
      "            methods: List of detection methods to use\n",
      "            \n",
      "        Returns:\n",
      "            Plotly figure with change points\n",
      "        \"\"\"\n",
      "        if methods is None:\n",
      "            methods = ['cusum', 'pettitt']\n",
      "            \n",
      "        fig = go.Figure()\n",
      "        \n",
      "        # Plot original data\n",
      "        fig.add_trace(\n",
      "            go.Scatter(\n",
      "                x=self.analyzer.data.index,\n",
      "                y=self.analyzer.data[column],\n",
      "                name='Original',\n",
      "                line=dict(color='blue')\n",
      "            )\n",
      "        )\n",
      "        \n",
      "        colors = {'cusum': 'red', 'pettitt': 'green'}\n",
      "        \n",
      "        # Add change points for each method\n",
      "        for method in methods:\n",
      "            change_points = self.analyzer.detect_change_points(column, method=method)\n",
      "            if change_points.any():\n",
      "                # Plot vertical lines at change points\n",
      "                for idx in self.analyzer.data.index[change_points]:\n",
      "                    fig.add_vline(\n",
      "                        x=idx,\n",
      "                        line_dash=\"dash\",\n",
      "                        line_color=colors[method],\n",
      "                        opacity=0.5,\n",
      "                        name=f\"{method.upper()} Change Point\"\n",
      "                    )\n",
      "        \n",
      "        fig.update_layout(\n",
      "            height=600,\n",
      "            width=1200,\n",
      "            title_text=f\"Change Point Detection for {column}\",\n",
      "            showlegend=True,\n",
      "            hovermode='x unified'\n",
      "        )\n",
      "        \n",
      "        return fig\n",
      "    \n",
      "    def create_interactive_dashboard(self, column: str) -> go.Figure:\n",
      "        \"\"\"Create an interactive dashboard with all analyses.\n",
      "        \n",
      "        Args:\n",
      "            column: Name of the column to analyze\n",
      "            \n",
      "        Returns:\n",
      "            Plotly figure with interactive dashboard\n",
      "        \"\"\"\n",
      "        fig = make_subplots(\n",
      "            rows=3, cols=2,\n",
      "            subplot_titles=(\n",
      "                'Time Series with Trend',\n",
      "                'Decomposition',\n",
      "                'Change Points (CUSUM)',\n",
      "                'Change Points (Pettitt)',\n",
      "                'Seasonal Pattern',\n",
      "                'Residual Analysis'\n",
      "            ),\n",
      "            vertical_spacing=0.12,\n",
      "            horizontal_spacing=0.1\n",
      "        )\n",
      "        \n",
      "        # Get all analyses\n",
      "        trend_analysis = self.analyzer.analyze_trend(column)\n",
      "        components = self.analyzer.decompose(column)\n",
      "        cusum_changes = self.analyzer.detect_change_points(column, method='cusum')\n",
      "        pettitt_changes = self.analyzer.detect_change_points(column, method='pettitt')\n",
      "        \n",
      "        # 1. Time Series with Trend\n",
      "        fig.add_trace(\n",
      "            go.Scatter(\n",
      "                x=self.analyzer.data.index,\n",
      "                y=self.analyzer.data[column],\n",
      "                name='Original',\n",
      "                line=dict(color='blue')\n",
      "            ),\n",
      "            row=1, col=1\n",
      "        )\n",
      "        fig.add_trace(\n",
      "            go.Scatter(\n",
      "                x=self.analyzer.data.index,\n",
      "                y=trend_analysis['trend_line'],\n",
      "                name='Trend',\n",
      "                line=dict(color='red', dash='dash')\n",
      "            ),\n",
      "            row=1, col=1\n",
      "        )\n",
      "        \n",
      "        # 2. Decomposition\n",
      "        fig.add_trace(\n",
      "            go.Scatter(\n",
      "                x=self.analyzer.data.index,\n",
      "                y=components['trend'],\n",
      "                name='Trend Component',\n",
      "                line=dict(color='purple')\n",
      "            ),\n",
      "            row=1, col=2\n",
      "        )\n",
      "        \n",
      "        # 3. CUSUM Change Points\n",
      "        fig.add_trace(\n",
      "            go.Scatter(\n",
      "                x=self.analyzer.data.index,\n",
      "                y=self.analyzer.data[column],\n",
      "                name='Original',\n",
      "                line=dict(color='blue'),\n",
      "                showlegend=False\n",
      "            ),\n",
      "            row=2, col=1\n",
      "        )\n",
      "        for idx in self.analyzer.data.index[cusum_changes]:\n",
      "            fig.add_vline(\n",
      "                x=idx,\n",
      "                line_dash=\"dash\",\n",
      "                line_color=\"red\",\n",
      "                opacity=0.5,\n",
      "                row=2, col=1\n",
      "            )\n",
      "            \n",
      "        # 4. Pettitt Change Points\n",
      "        fig.add_trace(\n",
      "            go.Scatter(\n",
      "                x=self.analyzer.data.index,\n",
      "                y=self.analyzer.data[column],\n",
      "                name='Original',\n",
      "                line=dict(color='blue'),\n",
      "                showlegend=False\n",
      "            ),\n",
      "            row=2, col=2\n",
      "        )\n",
      "        for idx in self.analyzer.data.index[pettitt_changes]:\n",
      "            fig.add_vline(\n",
      "                x=idx,\n",
      "                line_dash=\"dash\",\n",
      "                line_color=\"green\",\n",
      "                opacity=0.5,\n",
      "                row=2, col=2\n",
      "            )\n",
      "            \n",
      "        # 5. Seasonal Pattern\n",
      "        fig.add_trace(\n",
      "            go.Scatter(\n",
      "                x=self.analyzer.data.index,\n",
      "                y=components['seasonal'],\n",
      "                name='Seasonal',\n",
      "                line=dict(color='green')\n",
      "            ),\n",
      "            row=3, col=1\n",
      "        )\n",
      "        \n",
      "        # 6. Residual Analysis\n",
      "        fig.add_trace(\n",
      "            go.Scatter(\n",
      "                x=self.analyzer.data.index,\n",
      "                y=components['residual'],\n",
      "                name='Residual',\n",
      "                line=dict(color='gray')\n",
      "            ),\n",
      "            row=3, col=2\n",
      "        )\n",
      "        \n",
      "        # Update layout\n",
      "        fig.update_layout(\n",
      "            height=1000,\n",
      "            width=1200,\n",
      "            title_text=f\"Time Series Analysis Dashboard for {column}\",\n",
      "            showlegend=True,\n",
      "            hovermode='x unified'\n",
      "        )\n",
      "        \n",
      "        return fig\n",
      "    \n",
      "    # fig.update_layout(\n",
      "    #     height=1200,\n",
      "    #     width=1600,\n",
      "    #     showlegend=True,\n",
      "    #     title_text=\"Comprehensive Time Series Analysis Dashboard\"\n",
      "    # )\n",
      "    \n",
      "    # return fig\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "from specialized_viz.timeseries.visualization import TimeseriesVisualizer\n",
    "\n",
    "print(\"File contents:\")\n",
    "print(inspect.getsource(TimeseriesVisualizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package directory: c:\\apoorv\\projects\\specialized-viz\\specialized_viz\n",
      "Timeseries directory: c:\\apoorv\\projects\\specialized-viz\\specialized_viz\\timeseries\n",
      "Contents: ['analysis.py', 'forecasting.py', 'visualization.py', '__init__.py', '__pycache__']\n",
      "Visualization file exists: True\n",
      "First few lines of visualization.py:\n",
      "\"\"\"Enhanced time series visualization module for specialized-viz library.\"\"\"\n",
      "\n",
      "import plotly.graph_objects as go\n",
      "from plotly.subplots import make_subplots\n",
      "import plotly.express as px\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "from typing import Dict, List, Optional, Union\n",
      "import shap\n",
      "from .analysis import TimeseriesAnalysis\n",
      "\n",
      "class TimeseriesVisualizer:\n",
      "    \"\"\"Enhanced visualization class for time series analysis.\"\"\"\n",
      "    \n",
      "    def __init__(self, analyzer: TimeseriesAnalysis):\n",
      "        \"\"\"Initialize visu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import specialized_viz\n",
    "\n",
    "# Get the package directory\n",
    "package_dir = os.path.dirname(specialized_viz.__file__)\n",
    "timeseries_dir = os.path.join(package_dir, 'timeseries')\n",
    "\n",
    "print(\"Package directory:\", package_dir)\n",
    "print(\"Timeseries directory:\", timeseries_dir)\n",
    "print(\"Contents:\", os.listdir(timeseries_dir))\n",
    "\n",
    "# Let's also verify the visualization file\n",
    "viz_file = os.path.join(timeseries_dir, 'visualization.py')\n",
    "print(\"Visualization file exists:\", os.path.exists(viz_file))\n",
    "\n",
    "if os.path.exists(viz_file):\n",
    "    with open(viz_file, 'r') as f:\n",
    "        print(\"First few lines of visualization.py:\")\n",
    "        print(f.read()[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "github",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
